{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64\n",
    "image_directory = 'datasets/'\n",
    "\n",
    "no_tumor_images=os.listdir(image_directory+ 'crop_no/')\n",
    "yes_tumor_images=os.listdir(image_directory+ 'crop_yes/')\n",
    "dataset=[]\n",
    "label=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , image_name in enumerate(no_tumor_images) :\n",
    "    if(image_name.split('.')[1] == 'jpg') :\n",
    "        image=cv2.imread(image_directory+ 'crop_no/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUT_SIZE, INPUT_SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "\n",
    "for i , image_name in enumerate(yes_tumor_images) :\n",
    "    if(image_name.split('.')[1] == 'jpg') :\n",
    "        image=cv2.imread(image_directory+ 'crop_yes/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUT_SIZE,INPUT_SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 64, 64, 3)\n",
      "[[[[  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]]\n",
      "\n",
      "  [[  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]]\n",
      "\n",
      "  [[  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  4.   4.   4.]\n",
      "   [  0.   0.   0.]\n",
      "   [  2.   2.   2.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  4.   4.   4.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  2.   2.   2.]]\n",
      "\n",
      "  [[  1.   1.   1.]\n",
      "   [  3.   3.   3.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 85.  85.  85.]\n",
      "   [ 71.  71.  71.]\n",
      "   [ 72.  72.  72.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[ 60.  60.  60.]\n",
      "   [ 63.  63.  63.]\n",
      "   [ 94.  94.  94.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[ 94.  94.  94.]\n",
      "   [ 57.  57.  57.]\n",
      "   [ 99.  99.  99.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 91.  91.  91.]\n",
      "   [ 56.  56.  56.]\n",
      "   [ 72.  72.  72.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[ 97.  97.  97.]\n",
      "   [ 58.  58.  58.]\n",
      "   [ 76.  76.  76.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[104. 104. 104.]\n",
      "   [ 83.  83.  83.]\n",
      "   [ 56.  56.  56.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[176. 176. 176.]\n",
      "   [175. 175. 175.]\n",
      "   [185. 185. 185.]\n",
      "   ...\n",
      "   [207. 207. 207.]\n",
      "   [197. 197. 197.]\n",
      "   [192. 192. 192.]]\n",
      "\n",
      "  [[175. 175. 175.]\n",
      "   [179. 179. 179.]\n",
      "   [184. 184. 184.]\n",
      "   ...\n",
      "   [202. 202. 202.]\n",
      "   [192. 192. 192.]\n",
      "   [195. 195. 195.]]\n",
      "\n",
      "  [[179. 179. 179.]\n",
      "   [178. 178. 178.]\n",
      "   [182. 182. 182.]\n",
      "   ...\n",
      "   [188. 188. 188.]\n",
      "   [179. 179. 179.]\n",
      "   [195. 195. 195.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[193. 193. 193.]\n",
      "   [192. 192. 192.]\n",
      "   [196. 196. 196.]\n",
      "   ...\n",
      "   [192. 192. 192.]\n",
      "   [193. 193. 193.]\n",
      "   [193. 193. 193.]]\n",
      "\n",
      "  [[190. 190. 190.]\n",
      "   [191. 191. 191.]\n",
      "   [189. 189. 189.]\n",
      "   ...\n",
      "   [199. 199. 199.]\n",
      "   [197. 197. 197.]\n",
      "   [194. 194. 194.]]\n",
      "\n",
      "  [[186. 186. 186.]\n",
      "   [185. 185. 185.]\n",
      "   [179. 179. 179.]\n",
      "   ...\n",
      "   [201. 201. 201.]\n",
      "   [193. 193. 193.]\n",
      "   [203. 203. 203.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  1.   1.   1.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  1.   1.   1.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  1.   1.   1.]\n",
      "   [  1.   1.   1.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.   0.]\n",
      "   [  3.   3.   3.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  1.   1.   1.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[  0.   0.   0.]\n",
      "   [  4.   4.   4.]\n",
      "   [  0.   0.   0.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[143. 143. 143.]\n",
      "   [154. 154. 154.]\n",
      "   [145. 145. 145.]\n",
      "   ...\n",
      "   [218. 218. 218.]\n",
      "   [212. 212. 212.]\n",
      "   [ 69.  69.  69.]]\n",
      "\n",
      "  [[181. 181. 181.]\n",
      "   [194. 194. 194.]\n",
      "   [169. 169. 169.]\n",
      "   ...\n",
      "   [185. 185. 185.]\n",
      "   [253. 253. 253.]\n",
      "   [ 96.  96.  96.]]\n",
      "\n",
      "  [[189. 189. 189.]\n",
      "   [178. 178. 178.]\n",
      "   [154. 154. 154.]\n",
      "   ...\n",
      "   [211. 211. 211.]\n",
      "   [253. 253. 253.]\n",
      "   [148. 148. 148.]]]]\n",
      "[[[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.01568627 0.01568627 0.01568627]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.01568627 0.01568627 0.01568627]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]]\n",
      "\n",
      "\n",
      " [[[0.33333333 0.33333333 0.33333333]\n",
      "   [0.27843137 0.27843137 0.27843137]\n",
      "   [0.28235294 0.28235294 0.28235294]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.23529412 0.23529412 0.23529412]\n",
      "   [0.24705882 0.24705882 0.24705882]\n",
      "   [0.36862745 0.36862745 0.36862745]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.36862745 0.36862745 0.36862745]\n",
      "   [0.22352941 0.22352941 0.22352941]\n",
      "   [0.38823529 0.38823529 0.38823529]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.35686275 0.35686275 0.35686275]\n",
      "   [0.21960784 0.21960784 0.21960784]\n",
      "   [0.28235294 0.28235294 0.28235294]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.38039216 0.38039216 0.38039216]\n",
      "   [0.22745098 0.22745098 0.22745098]\n",
      "   [0.29803922 0.29803922 0.29803922]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.40784314 0.40784314 0.40784314]\n",
      "   [0.3254902  0.3254902  0.3254902 ]\n",
      "   [0.21960784 0.21960784 0.21960784]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.69019608 0.69019608 0.69019608]\n",
      "   [0.68627451 0.68627451 0.68627451]\n",
      "   [0.7254902  0.7254902  0.7254902 ]\n",
      "   ...\n",
      "   [0.81176471 0.81176471 0.81176471]\n",
      "   [0.77254902 0.77254902 0.77254902]\n",
      "   [0.75294118 0.75294118 0.75294118]]\n",
      "\n",
      "  [[0.68627451 0.68627451 0.68627451]\n",
      "   [0.70196078 0.70196078 0.70196078]\n",
      "   [0.72156863 0.72156863 0.72156863]\n",
      "   ...\n",
      "   [0.79215686 0.79215686 0.79215686]\n",
      "   [0.75294118 0.75294118 0.75294118]\n",
      "   [0.76470588 0.76470588 0.76470588]]\n",
      "\n",
      "  [[0.70196078 0.70196078 0.70196078]\n",
      "   [0.69803922 0.69803922 0.69803922]\n",
      "   [0.71372549 0.71372549 0.71372549]\n",
      "   ...\n",
      "   [0.7372549  0.7372549  0.7372549 ]\n",
      "   [0.70196078 0.70196078 0.70196078]\n",
      "   [0.76470588 0.76470588 0.76470588]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.75686275 0.75686275 0.75686275]\n",
      "   [0.75294118 0.75294118 0.75294118]\n",
      "   [0.76862745 0.76862745 0.76862745]\n",
      "   ...\n",
      "   [0.75294118 0.75294118 0.75294118]\n",
      "   [0.75686275 0.75686275 0.75686275]\n",
      "   [0.75686275 0.75686275 0.75686275]]\n",
      "\n",
      "  [[0.74509804 0.74509804 0.74509804]\n",
      "   [0.74901961 0.74901961 0.74901961]\n",
      "   [0.74117647 0.74117647 0.74117647]\n",
      "   ...\n",
      "   [0.78039216 0.78039216 0.78039216]\n",
      "   [0.77254902 0.77254902 0.77254902]\n",
      "   [0.76078431 0.76078431 0.76078431]]\n",
      "\n",
      "  [[0.72941176 0.72941176 0.72941176]\n",
      "   [0.7254902  0.7254902  0.7254902 ]\n",
      "   [0.70196078 0.70196078 0.70196078]\n",
      "   ...\n",
      "   [0.78823529 0.78823529 0.78823529]\n",
      "   [0.75686275 0.75686275 0.75686275]\n",
      "   [0.79607843 0.79607843 0.79607843]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.01568627 0.01568627 0.01568627]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.56078431 0.56078431 0.56078431]\n",
      "   [0.60392157 0.60392157 0.60392157]\n",
      "   [0.56862745 0.56862745 0.56862745]\n",
      "   ...\n",
      "   [0.85490196 0.85490196 0.85490196]\n",
      "   [0.83137255 0.83137255 0.83137255]\n",
      "   [0.27058824 0.27058824 0.27058824]]\n",
      "\n",
      "  [[0.70980392 0.70980392 0.70980392]\n",
      "   [0.76078431 0.76078431 0.76078431]\n",
      "   [0.6627451  0.6627451  0.6627451 ]\n",
      "   ...\n",
      "   [0.7254902  0.7254902  0.7254902 ]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.37647059 0.37647059 0.37647059]]\n",
      "\n",
      "  [[0.74117647 0.74117647 0.74117647]\n",
      "   [0.69803922 0.69803922 0.69803922]\n",
      "   [0.60392157 0.60392157 0.60392157]\n",
      "   ...\n",
      "   [0.82745098 0.82745098 0.82745098]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.58039216 0.58039216 0.58039216]]]]\n"
     ]
    }
   ],
   "source": [
    "np.array(dataset)\n",
    "label = np.array(label)\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.2 )\n",
    "\n",
    "x_train = np.array(x_train, dtype=float)\n",
    "x_test= np.array(x_test, dtype=float)\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train_normalized=x_train/255 # chia khoảng từ 0-1\n",
    "x_test_normalized=x_test/255 # chia khoảng từ 0-1\n",
    "\n",
    "y_train=to_categorical(y_train, num_classes=2) # đánh nhãn label theo dạng one-hot vector\n",
    "y_test=to_categorical(y_test, num_classes=2) \n",
    "\n",
    "\n",
    "print(x_train)\n",
    "print(x_train_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vu The Van\\miniconda3\\envs\\test\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential() # tuần tự nghĩa là các lớp được thêm vào theo thứ tự câu lệnh\n",
    "model.add(Conv2D(32, (3, 3),input_shape=(INPUT_SIZE, INPUT_SIZE, 3))) # gồm 3 lớp convolution xen kẽ với lớp pooling\n",
    "model.add(Activation('relu')) #công thức tính outpout 1 layer là A^l = activation(W^l x A^l-1 + B^l), relu :  max(0,x) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu')) # ví sao dùng activation: tạo sự phi tuyến tính + giữ output trong khoảng nhất định (0,1)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten()) # duỗi thẳng \n",
    "model.add(Dense(64)) # đưa qua 1 lớp 64 neuron\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(2)) # đưa qua lớp 2 neuron là : yes no\n",
    "model.add(Activation('sigmoid')) # 1/(1 + e^-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5981 - loss: 0.6933 - val_accuracy: 0.6760 - val_loss: 0.6085 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6811 - loss: 0.5830 - val_accuracy: 0.6580 - val_loss: 0.5692 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7451 - loss: 0.5119 - val_accuracy: 0.8040 - val_loss: 0.4466 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8139 - loss: 0.4041 - val_accuracy: 0.7960 - val_loss: 0.4182 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8487 - loss: 0.3399 - val_accuracy: 0.7460 - val_loss: 0.4571 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8641 - loss: 0.3085 - val_accuracy: 0.8080 - val_loss: 0.3661 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9096 - loss: 0.2202 - val_accuracy: 0.7800 - val_loss: 0.4015 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9019 - loss: 0.2197 - val_accuracy: 0.8100 - val_loss: 0.3885 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9293 - loss: 0.1577 - val_accuracy: 0.8180 - val_loss: 0.3896 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9549 - loss: 0.1227 - val_accuracy: 0.8420 - val_loss: 0.3381 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate=1e-3) \n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer1,\n",
    "    metrics=['accuracy'] \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "import log\n",
    "file_logging_callback  = log.FileLoggingCallback()\n",
    "\n",
    "model.fit(\n",
    "    x_train_normalized, \n",
    "    y_train, \n",
    "    batch_size=16,\n",
    "    verbose=1,\n",
    "    epochs=10, \n",
    "    validation_data=(x_test_normalized, y_test),\n",
    "    shuffle=True,\n",
    "    callbacks=[file_logging_callback, reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "#Lưu mô hình\n",
    "model.save('Braintumor10EpochsCategorical.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "F1 Score: 0.9370629370629371\n",
      "Accuracy của mô hình : 0.946\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model = load_model('Braintumor10EpochsCategorical.h5')\n",
    "\n",
    "# Dự đoán trên dữ liệu kiểm tra\n",
    "y_pred = model.predict(x_test_normalized)\n",
    "\n",
    "# Chuyển đổi xác suất thành nhãn phân loại\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Nếu y_test là one-hot encoded, chuyển đổi nó thành nhãn phân loại\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Tính toán F1 Score\n",
    "score = f1_score(y_test_classes, y_pred_classes)\n",
    "print(f\"F1 Score: {score}\")\n",
    "\n",
    "# Tính accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Accuracy của mô hình : {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
