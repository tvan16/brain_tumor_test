{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  1.IMPORT THƯ VIỆN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.CHUẨN BỊ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224  # Kích thước ảnh mà ResNet50 yêu cầu\n",
    "\n",
    "# Đường dẫn tới các thư mục ảnh\n",
    "image_directory = 'datasets/'\n",
    "\n",
    "# Lấy danh sách các ảnh từ các thư mục\n",
    "no_tumor_images = os.listdir(image_directory + 'crop_no/')\n",
    "yes_tumor_images = os.listdir(image_directory + 'crop_yes/')\n",
    "\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "# Đọc và xử lý ảnh không có khối u\n",
    "for image_name in no_tumor_images:\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory + 'crop_no/', image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUT_SIZE, INPUT_SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        labels.append(0)\n",
    "\n",
    "# Đọc và xử lý ảnh có khối u\n",
    "for image_name in yes_tumor_images:\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory + 'crop_yes/', image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUT_SIZE, INPUT_SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        labels.append(1)\n",
    "\n",
    "# Chuyển đổi dữ liệu thành numpy arrays\n",
    "dataset = np.array(dataset)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Chuẩn hóa dữ liệu: Đưa giá trị pixel về khoảng từ 0 đến 1\n",
    "x_train_normalized = x_train / 255.0\n",
    "x_test_normalized = x_test / 255.0\n",
    "\n",
    "\n",
    "# One-hot encode nhãn (labels)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.TẢI MÔ HÌNH RESNET50 PRE-TRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 với trọng số pre-trained, bỏ qua phần fully-connected layer cuối cùng\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
    "\n",
    "# Đóng băng các lớp của ResNet50 để không huấn luyện lại\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XÂY DỰNG MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.HUẤN LUYỆN MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 865ms/step - accuracy: 0.5400 - loss: 0.9301 - val_accuracy: 0.6120 - val_loss: 0.6529 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 844ms/step - accuracy: 0.6022 - loss: 0.6787 - val_accuracy: 0.6220 - val_loss: 0.6478 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 823ms/step - accuracy: 0.5997 - loss: 0.6796 - val_accuracy: 0.6260 - val_loss: 0.6452 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 830ms/step - accuracy: 0.6231 - loss: 0.6435 - val_accuracy: 0.6320 - val_loss: 0.6418 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 821ms/step - accuracy: 0.6437 - loss: 0.6277 - val_accuracy: 0.6460 - val_loss: 0.6336 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 822ms/step - accuracy: 0.6463 - loss: 0.6398 - val_accuracy: 0.6440 - val_loss: 0.6251 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 817ms/step - accuracy: 0.6720 - loss: 0.5993 - val_accuracy: 0.6600 - val_loss: 0.6149 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 827ms/step - accuracy: 0.6700 - loss: 0.6228 - val_accuracy: 0.6400 - val_loss: 0.6126 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 818ms/step - accuracy: 0.6480 - loss: 0.6242 - val_accuracy: 0.6160 - val_loss: 0.7240 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 807ms/step - accuracy: 0.6680 - loss: 0.6111 - val_accuracy: 0.6380 - val_loss: 0.6464 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x273ebb4a890>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train_normalized,\n",
    "    y_train,\n",
    "    batch_size=32,  \n",
    "    epochs=10,\n",
    "    validation_data=(x_test_normalized, y_test),\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.ĐÁNH GIÁ ĐỘ CHÍNH XÁC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 685ms/step\n",
      "Accuracy của mô hình sử dụng ResNet50: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập test\n",
    "y_pred = model.predict(x_test_normalized)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Tính accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Accuracy của mô hình sử dụng ResNet50: {accuracy}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
